# -*- coding: utf-8 -*-
"""AluguelBike.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lTtWkpg1HA3zk_72TLyYEB8uFLyfGgco
"""

#carregar as bibliotecas basicas
import numpy as np
import pandas as pd

#bibliotecas para plots
import seaborn as sns
import matplotlib.pyplot as plt
from matplotlib import rcParams
rcParams['figure.figsize'] = (16, 6)

"""LEITURA DOS DADOS"""

#leitura do dataset
df = pd.read_csv("https://pycourse.s3.amazonaws.com/bike-sharing.csv")
df.head()

#informações básicas
df.info()

"""PRÉ-PROCESSAMENTO"""

#date time conversion
df['datetime'] = pd.to_datetime(df['datetime'])

#variáveis categóricas
df['season'] = df['season'].astype('int')

df['is_holiday'] = df['is_holiday'].astype('int')

df['weekday'] = df['weekday'].astype('int')

df['weather_condition'] = df['weather_condition'].astype('int')

df['is_workingday'] = df['weather_condition'].astype('int')

df['month'] = df['month'].astype('int')

df['year'] = df['year'].astype('int')

df['hour'] = df['hour'].astype('int')

"""VISUZLIZAÇÕES"""

#plot inicial 
df.plot(x='datetime', y='total_count');

#Quantidade de registros em 2011
df.loc[df['year']==0]

#Quantidade de registros 2012
df.loc[df['year']==1]

#soma do total de locações
df.total_count.sum()



#tendências horárias
fig, ax = plt.subplots(nrows=2, sharex=True, figsize=(16, 10))

sns.pointplot(data=df, x='hour', y='total_count', hue='season', ax=ax[0])
ax[0].set_title("Locações horárias de bicicletas por estação do ano")
ax[0].grid()

sns.pointplot(data=df, x='hour', y='total_count', hue='weekday', ax=ax[1])
ax[1].set_title("Locações horárias de bicicletas por dia da semana")
ax[1].grid();

#medias
df.mean()

#distribuição por mês
fig, ax = plt.subplots()
sns.barplot(data=df, x="month", y="total_count")
ax.set_title("Distribuição mensal das locações");

#distribuição por estação do ano
fig, ax = plt.subplots()
sns.barplot(data=df, x="season", y="total_count")
ax.set_title("Distribuição por estação do ano")

#distribuição por ano
fig, ax = plt.subplots()
sns.barplot(data=df, x="year", y="total_count", estimator=sum, ci=None)
ax.set_title("Locações por ano")



#outliers
fig, ax = plt.subplots(ncols=2)
sns.boxplot(data=df[['total_count', 'casual', 'registered']], ax=ax[0])
sns.boxplot(data=df[['temp', 'windspeed', 'humidity']], ax=ax[1]);

#Média dos valores
df.mean()

df.describe()

#outliers: uso horário
fig, ax = plt.subplots()
sns.boxplot(data=df, x='hour', y='total_count');

#correlação
plt.figure(figsize=(30, 10))

#extraíndo matrix de correlação
corr_mat = df[['temp', 'atemp', 'humidity', 'windspeed',
               'casual', 'registered']].corr()

#visualização dos elementos abaixo da diagonal principal
mask = np.array(corr_mat)
mask[np.tril_indices_from(mask)] = False

#plot 
sns.heatmap(corr_mat, mask=mask, square=True, annot=True)
plt.show()

"""MODELO PREDITIVO DE LOCAÇÕES - previsão de demanda diária de bicicletas"""

# pré-processamento dos dados: remoção de colunas desnecessárias
df.drop(['rec_id',
         'casual',
         'registered',
         'atemp',
         'year',
         'hour'],
        axis=1,
        inplace=True)

# visualização das primeiras linhas
df.head()

#agrupando pelo datetime
df = df.groupby('datetime', as_index=False).mean()

# agora com os dados agrupados
df.head()

#visualização dos dados agrupados
df.plot(x='datetime', y='total_count');

"""PARA MODELO TEMPORAL, USAMOS O total_count DO DIA ANTERIOR COMO VARIÁVEL EXÓGENA PARA O MODELO"""

# gerando a série defasada total_count: lag1
df['total_count_lag1'] = np.r_[df.iloc[0, -1], df.iloc[:-1, 1]]

#nova coluna
df.head(10)

#ajustando os dtypes
df['season'] = df['season'].astype('int')
df['month'] = df['month'].astype('int')
df['is_holiday'] = df['is_holiday'].astype('int')
df['weekday'] = df['weekday'].astype('int')
df['is_workingday'] = df['is_workingday'].astype('int')

#codificação das variáveis categóricas: one hot encoding
df = pd.get_dummies(df, columns=['season', 'month', 'weekday'])

df.head()

# divisão em treino (90%) e teste (10%)
n, p = df.shape[0], 0.9

df_train = df.iloc[:int(n*p), 1:]
dtime_train = df.iloc[:int(n*p), 0]

df_test = df.iloc[int(n*p):, 1:]
dtime_test = df.iloc[int(n*p):, 0]

print("df_train shape:", df_train.shape)
print("df_test shape:", df_test.shape)

#extração de x_train, x_test, y_train, y_test
x_train = df_train.drop('total_count', axis=1)
y_train = df_train['total_count']

x_test = df_test.drop('total_count', axis=1)
y_test = df_test['total_count']

#model 
from sklearn.ensemble import RandomForestRegressor

# fit model
model = RandomForestRegressor(random_state=0)
model.fit(x_train, y_train)

#predição
y_pred = model.predict(x_test)

#intervalo de confiança
n_steps = 3
ts_pred = pd.DataFrame(y_pred)
smooth_path     = ts_pred.rolling(n_steps).mean()
path_deviation  = 1.96 * ts_pred.rolling(n_steps).std()

under_line = (smooth_path-path_deviation)[0]
over_line = (smooth_path+path_deviation)[0]

# visualização
plt.plot(dtime_test, y_pred, linewidth=2, label='predição')
plt.fill_between(dtime_test, under_line, over_line, color='b', alpha=.15)
plt.plot(dtime_test, y_test, label='real')
plt.xticks(dtime_test.iloc[np.arange(dtime_test.size, step= 10).astype(int)])
plt.legend()
plt.grid()
plt.title("Predição do número de locações diárias de bicicletas")
plt.show()

# importâncias das features
fp = model.feature_importances_
n = 5
i = np.argsort(fp)[-n:]
cols = x_train.columns
plt.barh(cols[i], fp[i])
plt.grid()
plt.title(f"{n} features mais importantes")
plt.xlabel("Importância relativa")
plt.ylabel("Feature")
plt.show()